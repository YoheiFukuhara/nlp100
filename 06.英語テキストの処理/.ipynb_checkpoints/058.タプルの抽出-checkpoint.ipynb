{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stanford Core NLPの係り受け解析の結果（collapsed-dependencies）に基づき，「主語 述語 目的語」の組をタブ区切り形式で出力せよ．ただし，主語，述語，目的語の定義は以下を参考にせよ．\n",
    "- 述語: nsubj関係とdobj関係の子（dependant）を持つ単語\n",
    "- 主語: 述語からnsubj関係にある子（dependent）\n",
    "- 目的語: 述語からdobj関係にある子（dependent）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "import xml.etree.ElementTree as ET\n",
    "import pydot_ng as pydot    \n",
    "#なぜかpipでpydot_ngをインストールしただけだと「GraphViz's executables not found」エラーが起きたため、\n",
    "# sudo apt install graphvizでOSにインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = './nlp.txt'\n",
    "fname_parsed = './nlp.txt.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_nlp():\n",
    "    '''nlp.txtをStanford Core NLPで解析しxmlファイルへ出力\n",
    "    すでに結果ファイルが存在する場合は実行しない\n",
    "    '''\n",
    "    if not os.path.exists(fname_parsed):\n",
    "\n",
    "        # StanfordCoreNLP実行、標準エラーはparse.outへ出力\n",
    "        subprocess.run(\n",
    "            'java -cp \"/usr/local/lib/stanford-corenlp-full-2018-10-05/*\"'\n",
    "            ' -Xmx4g'\n",
    "            ' edu.stanford.nlp.pipeline.StanfordCoreNLP'\n",
    "            ' -annotators tokenize,ssplit,pos,lemma,ner,parse,dcoref'\n",
    "            ' -file ' + fname + ' 2>parse.out',\n",
    "            shell=True,     # shellで実行\n",
    "            check=True      # エラーチェックあり\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_from_edges_ex(edge_list, directed=False):\n",
    "    '''pydot_ng.graph_from_edges()のノード識別子への対応版\n",
    "\n",
    "    graph_from_edges()のedge_listで指定するタプルは\n",
    "    識別子とグラフ表示時のラベルが同一のため、\n",
    "    ラベルが同じだが実体が異なるノードを表現することができない。\n",
    "    例えば文の係り受けをグラフにする際、文の中に同じ単語が\n",
    "    複数出てくると、それらのノードが同一視されて接続されてしまう。\n",
    "\n",
    "    この関数ではedge_listとして次の書式のタプルを受け取り、\n",
    "    ラベルが同一でも識別子が異なるノードは別ものとして扱う。\n",
    "\n",
    "    edge_list = [((識別子1,ラベル1),(識別子2,ラベル2)), ...]\n",
    "\n",
    "    識別子はノードを識別するためのもので表示されない。\n",
    "    ラベルは表示用で、同じでも識別子が異なれば別のノードになる。\n",
    "\n",
    "    なお、オリジナルの関数にあるnode_prefixは未実装。\n",
    "\n",
    "    戻り値：\n",
    "    pydot.Dotオブジェクト\n",
    "    '''\n",
    "\n",
    "    if directed:\n",
    "        graph = pydot.Dot(graph_type='digraph')\n",
    "\n",
    "    else:\n",
    "        graph = pydot.Dot(graph_type='graph')\n",
    "\n",
    "    for edge in edge_list:\n",
    "\n",
    "        id1 = str(edge[0][0])\n",
    "        label1 = str(edge[0][1])\n",
    "        id2 = str(edge[1][0])\n",
    "        label2 = str(edge[1][1])\n",
    "\n",
    "        # ノード追加\n",
    "        graph.add_node(pydot.Node(id1, label=label1))\n",
    "        graph.add_node(pydot.Node(id2, label=label2))\n",
    "\n",
    "        # エッジ追加\n",
    "        graph.add_edge(pydot.Edge(id1, id2))\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.txtを解析\n",
    "parse_nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析結果のxmlをパース\n",
    "root = ET.parse(fname_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence列挙、1文ずつ処理\n",
    "for sentence in root.iterfind('./document/sentences/sentence'):\n",
    "    #sent_id = int(sentence.get('id'))       # sentenceのid\n",
    "    sent_id = '57_' + sentence.get('id').rjust(2,'0')       # 接頭辞57_とゼロパディングのsentence id\n",
    "\n",
    "    edges = []\n",
    "\n",
    "    # dependencies列挙\n",
    "    for dep in sentence.iterfind(\n",
    "        './dependencies[@type=\"collapsed-dependencies\"]/dep'\n",
    "    ):\n",
    "\n",
    "        # 句読点はスキップ\n",
    "        if dep.get('type') != 'punct':\n",
    "\n",
    "            # governor、dependent取得、edgesに追加\n",
    "            govr = dep.find('./governor')\n",
    "            dept = dep.find('./dependent')\n",
    "            edges.append(\n",
    "                ((govr.get('idx'), govr.text), (dept.get('idx'), dept.text))\n",
    "            )\n",
    "\n",
    "    # 描画\n",
    "    if len(edges) > 0:\n",
    "        graph = graph_from_edges_ex(edges, directed=True)\n",
    "        graph.write_png('{}.png'.format(sent_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
