{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stanford Core NLPの係り受け解析の結果（collapsed-dependencies）に基づき，「主語 述語 目的語」の組をタブ区切り形式で出力せよ．ただし，主語，述語，目的語の定義は以下を参考にせよ．\n",
    "- 述語: nsubj関係とdobj関係の子（dependant）を持つ単語\n",
    "- 主語: 述語からnsubj関係にある子（dependent）\n",
    "- 目的語: 述語からdobj関係にある子（dependent）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = './nlp.txt'\n",
    "fname_parsed = './nlp.txt.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_nlp():\n",
    "    '''nlp.txtをStanford Core NLPで解析しxmlファイルへ出力\n",
    "    すでに結果ファイルが存在する場合は実行しない\n",
    "    '''\n",
    "    if not os.path.exists(fname_parsed):\n",
    "\n",
    "        # StanfordCoreNLP実行、標準エラーはparse.outへ出力\n",
    "        subprocess.run(\n",
    "            'java -cp \"/usr/local/lib/stanford-corenlp-full-2018-10-05/*\"'\n",
    "            ' -Xmx4g'\n",
    "            ' edu.stanford.nlp.pipeline.StanfordCoreNLP'\n",
    "            ' -annotators tokenize,ssplit,pos,lemma,ner,parse,dcoref'\n",
    "            ' -file ' + fname + ' 2>parse.out',\n",
    "            shell=True,     # shellで実行\n",
    "            check=True      # エラーチェックあり\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.txtを解析\n",
    "parse_nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析結果のxmlをパース\n",
    "root = ET.parse(fname_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "understanding\tenabling\tcomputers\n",
      "others\tinvolve\tgeneration\n",
      "Turing\tpublished\tarticle\n",
      "experiment\tinvolved\ttranslation\n",
      "ELIZA\tprovided\tinteraction\n",
      "ELIZA\tprovide\tresponse\n",
      "patient\texceeded\tbase\n",
      "which\tstructured\tinformation\n",
      "underpinnings\tdiscouraged\tsort\n",
      "that\tunderlies\tapproach\n",
      "Some\tproduced\tsystems\n",
      "which\tmake\tdecisions\n",
      "systems\trely\twhich\n",
      "that\tcontains\terrors\n",
      "implementations\tinvolved\tcoding\n",
      "algorithms\ttake\tset\n",
      "Some\tproduced\tsystems\n",
      "which\tmake\tdecisions\n",
      "models\thave\tadvantage\n",
      "they\texpress\tcertainty\n",
      "Systems\thave\tadvantages\n",
      "Automatic\tmake\tuse\n",
      "that\tmake\tdecisions\n"
     ]
    }
   ],
   "source": [
    "# sentence列挙、1文ずつ処理\n",
    "for sentence in root.iterfind('./document/sentences/sentence'):\n",
    "    sent_id = int(sentence.get('id'))       # sentenceのid\n",
    "\n",
    "    # それぞれの語の辞書を作成\n",
    "    dict_pred = {}      # {述語のidx, 述語のtext}\n",
    "    dict_nsubj = {}     # {述語のidx, 述語とnsubj関係の子のtext（＝主語）}\n",
    "    dict_dobj = {}      # {述語のidx, 述語とdobj関係の子のtext（＝目的語）}\n",
    "\n",
    "    # dependencies列挙\n",
    "    for dep in sentence.iterfind(\n",
    "        './dependencies[@type=\"collapsed-dependencies\"]/dep'\n",
    "    ):\n",
    "\n",
    "        # 関係チェック\n",
    "        dep_type = dep.get('type')\n",
    "        if dep_type == 'nsubj' or dep_type == 'dobj':\n",
    "\n",
    "            # 述語の辞書に追加\n",
    "            govr = dep.find('./governor')\n",
    "            idx = govr.get('idx')\n",
    "            dict_pred[idx] = govr.text      # 重複するが無害なのでチェックは省略\n",
    "\n",
    "            # 主語or目的語の辞書に追加\n",
    "            if dep_type == 'nsubj':\n",
    "                dict_nsubj[idx] = dep.find('./dependent').text\n",
    "            else:\n",
    "                dict_dobj[idx] = dep.find('./dependent').text\n",
    "\n",
    "    # 述語を列挙、主語と目的語の両方を持つもののみ出力\n",
    "    for idx, pred in sorted(dict_pred.items(), key=lambda x: x[0]):\n",
    "        nsubj = dict_nsubj.get(idx)\n",
    "        dobj = dict_dobj.get(idx)\n",
    "        if nsubj is not None and dobj is not None:\n",
    "            print('{}\\t{}\\t{}'.format(nsubj, pred, dobj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
