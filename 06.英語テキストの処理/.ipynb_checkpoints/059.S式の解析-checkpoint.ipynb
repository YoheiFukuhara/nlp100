{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stanford Core NLPの句構造解析の結果（S式）を読み込み，文中のすべての名詞句（NP）を表示せよ．入れ子になっている名詞句もすべて表示すること"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess, re\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = './nlp.txt'\n",
    "fname_parsed = './nlp.txt.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# タグと内容を抽出するための正規表現\n",
    "pattern = re.compile(r'''\n",
    "    ^\n",
    "    \\(          # S式の開始カッコ\n",
    "        (.*?)   # = タグ\n",
    "        \\s      # 空白\n",
    "        (.*)    # = 内容\n",
    "    \\)          # s式の終わりのカッコ\n",
    "    $\n",
    "    ''', re.VERBOSE + re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_nlp():\n",
    "    '''nlp.txtをStanford Core NLPで解析しxmlファイルへ出力\n",
    "    すでに結果ファイルが存在する場合は実行しない\n",
    "    '''\n",
    "    if not os.path.exists(fname_parsed):\n",
    "\n",
    "        # StanfordCoreNLP実行、標準エラーはparse.outへ出力\n",
    "        subprocess.run(\n",
    "            'java -cp \"/usr/local/lib/stanford-corenlp-full-2018-10-05/*\"'\n",
    "            ' -Xmx4g'\n",
    "            ' edu.stanford.nlp.pipeline.StanfordCoreNLP'\n",
    "            ' -annotators tokenize,ssplit,pos,lemma,ner,parse,dcoref'\n",
    "            ' -file ' + fname + ' 2>parse.out',\n",
    "            shell=True,     # shellで実行\n",
    "            check=True      # エラーチェックあり\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParseAndExtractNP(str, list_np):\n",
    "    '''S式をタグと内容に分解し内容のみを返す\n",
    "    またタグがNPの場合は、内容をlist_npにも追加する\n",
    "    内容が入れ子になっている場合は、\n",
    "    その中身も解析して、内容を空白区切りで返す。\n",
    "\n",
    "    戻り値：\n",
    "    タグを除いた内容\n",
    "    '''\n",
    "\n",
    "    # タグと内容を抽出\n",
    "    match = pattern.match(str)\n",
    "    tag = match.group(1)\n",
    "    value = match.group(2)\n",
    "\n",
    "    # 内容の解析\n",
    "    # カッコで入れ子になっている場合は、一番外側を切り出して再帰\n",
    "    depth = 0       # カッコの深さ\n",
    "    chunk = ''      # 切り出し中の文字列\n",
    "    words = []\n",
    "    for c in value:\n",
    "\n",
    "        if c == '(':\n",
    "            chunk += c\n",
    "            depth += 1      # 深くなった\n",
    "\n",
    "        elif c == ')':\n",
    "            chunk += c\n",
    "            depth -= 1      # 浅くなった\n",
    "            if depth == 0:\n",
    "                # 深さが戻ったので、カッコでくくられた部分の切り出し完了\n",
    "                # 切り出した部分はParseAndExtractNP()に任せる（再帰呼び出し）\n",
    "                words.append(ParseAndExtractNP(chunk, list_np))\n",
    "                chunk = ''\n",
    "        else:\n",
    "            # カッコでくくられていない部分の空白は無視\n",
    "            if not (depth == 0 and c == ' '):\n",
    "                chunk += c\n",
    "\n",
    "    # 最後の単語を追加\n",
    "    if chunk != '':\n",
    "        words.append(chunk)\n",
    "\n",
    "    # 空白区切りに整形\n",
    "    result = ' '.join(words)\n",
    "\n",
    "    # NPならlist_npに追加\n",
    "    if tag == 'NP':\n",
    "        list_np.append(result)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.txtを解析\n",
    "parse_nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析結果のxmlをパース\n",
    "root = ET.parse(fname_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing\n",
      "Wikipedia\n",
      "the free encyclopedia Natural language processing\n",
      "NLP\n",
      "the free encyclopedia Natural language processing -LRB- NLP -RRB-\n",
      "a field\n",
      "computer science\n",
      "a field of computer science\n",
      "artificial intelligence\n",
      "linguistics\n",
      "the interactions\n",
      "computers\n",
      "human -LRB- natural -RRB- languages\n",
      "computers and human -LRB- natural -RRB- languages\n",
      "the interactions between computers and human -LRB- natural -RRB- languages\n",
      "linguistics concerned with the interactions between computers and human -LRB- natural -RRB- languages\n",
      "a field of computer science , artificial intelligence , and linguistics concerned with the interactions between computers and human -LRB- natural -RRB- languages\n",
      "such\n",
      "NLP\n",
      "the area\n",
      "humani-computer interaction\n",
      "the area of humani-computer interaction\n",
      "Many challenges\n",
      "NLP\n",
      "Many challenges in NLP\n",
      "natural language understanding\n",
      "natural language understanding , that is ,\n",
      "computers\n",
      "meaning\n",
      "human or natural language input\n",
      "others\n",
      "natural language generation\n",
      "History The history\n",
      "NLP\n",
      "History The history of NLP\n",
      "the 1950s\n",
      "work\n",
      "earlier periods\n",
      "1950\n",
      "Alan Turing\n",
      "an article\n",
      "Computing Machinery and Intelligence\n",
      "the Turing test\n",
      "a criterion\n",
      "intelligence\n",
      "a criterion of intelligence\n",
      "an article titled `` Computing Machinery and Intelligence '' which proposed what is now called the Turing test as a criterion of intelligence\n",
      "The Georgetown experiment\n",
      "1954\n",
      "The Georgetown experiment in 1954\n",
      "fully automatic translation\n",
      "more than sixty Russian sentences\n",
      "fully automatic translation of more than sixty Russian sentences\n",
      "English\n",
      "The authors\n",
      "three or five years\n",
      "machine translation\n",
      "a solved problem\n",
      "real progress\n",
      "the ALPAC report\n",
      "1966\n",
      "long research\n",
      "the expectations\n",
      "the ALPAC report in 1966 , which found that ten year long research had failed to fulfill the expectations\n",
      "machine\n",
      "translation\n",
      "Little further research\n",
      "machine translation\n",
      "Little further research in machine translation\n",
      "the late 1980s\n",
      "the first statistical machine\n",
      "translation systems\n",
      "the first statistical machine translation systems\n",
      "the late 1980s , when the first statistical machine translation systems were developed\n",
      "Some notably successful NLP systems\n",
      "the 1960s\n",
      "Some notably successful NLP systems developed in the 1960s\n",
      "SHRDLU\n",
      "a natural language system\n",
      "restricted\n",
      "blocks worlds\n",
      "restricted `` blocks worlds ''\n",
      "restricted vocabularies\n",
      "a natural language system working in restricted `` blocks worlds '' with restricted vocabularies\n",
      "SHRDLU , a natural language system working in restricted `` blocks worlds '' with restricted vocabularies\n",
      "ELIZA\n",
      "a simulation\n",
      "a Rogerian psychotherapist\n",
      "a simulation of a Rogerian psychotherapist\n",
      "ELIZA , a simulation of a Rogerian psychotherapist ,\n",
      "Joseph Weizenbaum\n",
      "1964 to 1966\n",
      "Joseph Weizenbaum between 1964 to 1966\n",
      "almost no information\n",
      "human thought or emotion\n",
      "ELIZA\n",
      "a startlingly human-like interaction\n",
      "the `` patient ''\n",
      "the very small knowledge base\n",
      "ELIZA\n",
      "a generic response\n",
      "example\n",
      "My head\n",
      "a generic response , for example , responding to `` My head hurts\n",
      "you\n",
      "your head\n",
      ".\n",
      "the 1970s\n",
      "many programmers\n",
      "conceptual\n",
      "ontologies '\n",
      "conceptual ontologies '\n",
      "real-world information\n",
      "computer-understandable data\n",
      "conceptual ontologies ' , which structured real-world information into computer-understandable data\n",
      "Examples\n",
      "MARGIE\n",
      "Schank\n",
      "1975\n",
      "MARGIE -LRB- Schank , 1975 -RRB-\n",
      "SAM\n",
      "Cullingford\n",
      "1978\n",
      "SAM -LRB- Cullingford , 1978 -RRB-\n",
      "PAM\n",
      "Wilensky\n",
      "1978\n",
      "PAM -LRB- Wilensky , 1978 -RRB-\n",
      "TaleSpin\n",
      "Meehan\n",
      "1976\n",
      "TaleSpin -LRB- Meehan , 1976 -RRB-\n",
      "QUALM\n",
      "Lehnert\n",
      "1977\n",
      "Lehnert , 1977\n",
      "QUALM -LRB- Lehnert , 1977 -RRB-\n",
      "Politics\n",
      "Carbonell\n",
      "1979\n",
      "Politics -LRB- Carbonell , 1979 -RRB-\n",
      "Plot Units\n",
      "Lehnert 1981\n",
      "Plot Units -LRB- Lehnert 1981 -RRB-\n",
      "SAM -LRB- Cullingford , 1978 -RRB- , PAM -LRB- Wilensky , 1978 -RRB- , TaleSpin -LRB- Meehan , 1976 -RRB- , QUALM -LRB- Lehnert , 1977 -RRB- , Politics -LRB- Carbonell , 1979 -RRB- , and Plot Units -LRB- Lehnert 1981 -RRB-\n",
      "MARGIE -LRB- Schank , 1975 -RRB- , SAM -LRB- Cullingford , 1978 -RRB- , PAM -LRB- Wilensky , 1978 -RRB- , TaleSpin -LRB- Meehan , 1976 -RRB- , QUALM -LRB- Lehnert , 1977 -RRB- , Politics -LRB- Carbonell , 1979 -RRB- , and Plot Units -LRB- Lehnert 1981 -RRB-\n",
      "this time\n",
      "many chatterbots\n",
      "PARRY , Racter , and Jabberwacky\n",
      "the 1980s\n",
      "most NLP systems\n",
      "complex sets\n",
      "hand-written rules\n",
      "complex sets of hand-written rules\n",
      "the late 1980s\n",
      "there\n",
      "a revolution\n",
      "NLP\n",
      "a revolution in NLP\n",
      "the introduction\n",
      "machine learning algorithms\n",
      "language processing\n",
      "machine learning algorithms for language processing\n",
      "the introduction of machine learning algorithms for language processing\n",
      "This\n",
      "both the steady increase\n",
      "computational power\n",
      "Moore 's\n",
      "Moore 's Law\n",
      "the gradual lessening\n",
      "the dominance\n",
      "Chomskyan theories\n",
      "the dominance of Chomskyan theories\n",
      "linguistics\n",
      "e.g.\n",
      "transformational grammar\n",
      "e.g. transformational grammar\n",
      "linguistics -LRB- e.g. transformational grammar -RRB-\n",
      "theoretical underpinnings\n",
      "the sort\n",
      "corpus linguistics\n",
      "the machine-learning approach\n",
      "language processing\n",
      "the sort of corpus linguistics that underlies the machine-learning approach to language processing\n",
      "the gradual lessening of the dominance of Chomskyan theories of linguistics -LRB- e.g. transformational grammar -RRB- , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing\n",
      "Moore 's Law and the gradual lessening of the dominance of Chomskyan theories of linguistics -LRB- e.g. transformational grammar -RRB- , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing\n",
      "computational power resulting from Moore 's Law and the gradual lessening of the dominance of Chomskyan theories of linguistics -LRB- e.g. transformational grammar -RRB- , whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing\n",
      "Some\n",
      "the earliest-used machine\n",
      "algorithms\n",
      "decision trees\n",
      "algorithms , such as decision trees ,\n",
      "the earliest-used machine learning algorithms , such as decision trees ,\n",
      "Some of the earliest-used machine learning algorithms , such as decision trees ,\n",
      "systems\n",
      "hard if-then rules\n",
      "existing hand-written rules\n",
      "hard if-then rules similar to existing hand-written rules\n",
      "systems of hard if-then rules similar to existing hand-written rules\n",
      "Part\n",
      "speech\n",
      "Part of speech\n",
      "the use\n",
      "Hidden Markov Models\n",
      "the use of Hidden Markov Models\n",
      "NLP\n",
      "research\n",
      "statistical models\n",
      "soft , probabilistic decisions\n",
      "real-valued weights\n",
      "the features\n",
      "the input data\n",
      "the features making up the input data\n",
      "statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to the features making up the input data\n",
      "The cache language models\n",
      "many speech recognition systems\n",
      "The cache language models upon which many speech recognition systems now rely\n",
      "examples\n",
      "such statistical models\n",
      "examples of such statistical models\n",
      "Such models\n",
      "unfamiliar input\n",
      "input\n",
      "errors\n",
      "real-world data\n",
      "errors -LRB- as is very common for real-world data -RRB-\n",
      "input that contains errors -LRB- as is very common for real-world data -RRB-\n",
      "unfamiliar input , especially input that contains errors -LRB- as is very common for real-world data -RRB- ,\n",
      "more reliable results\n",
      "a larger system\n",
      "multiple subtasks\n",
      "a larger system comprising multiple subtasks\n",
      "Many\n",
      "the notable early successes\n",
      "Many of the notable early successes\n",
      "the field\n",
      "machine translation\n",
      "IBM Research\n",
      "more complicated statistical models\n",
      "machine translation , due especially to work at IBM Research , where successively more complicated statistical models were developed\n",
      "the field of machine translation , due especially to work at IBM Research , where successively more complicated statistical models were developed\n",
      "These systems\n",
      "advantage\n",
      "existing multilingual textual corpora\n",
      "the Parliament\n",
      "Canada\n",
      "the European Union\n",
      "Canada and the European Union\n",
      "the Parliament of Canada and the European Union\n",
      "a result\n",
      "laws\n",
      "the translation\n",
      "all governmental proceedings\n",
      "the translation of all governmental proceedings\n",
      "all official languages\n",
      "the corresponding systems\n",
      "government\n",
      "the corresponding systems of government\n",
      "all official languages of the corresponding systems of government\n",
      "laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government\n",
      "a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government\n",
      "existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government\n",
      "advantage of existing multilingual textual corpora that had been produced by the Parliament of Canada and the European Union as a result of laws calling for the translation of all governmental proceedings into all official languages of the corresponding systems of government\n",
      "most other systems\n",
      "corpora\n",
      "the tasks\n",
      "these systems\n",
      "these systems , which was -LRB- and often continues to be -RRB-\n",
      "the tasks implemented by these systems , which was -LRB- and often continues to be -RRB-\n",
      "a major limitation\n",
      "the success\n",
      "these systems\n",
      "the success of these systems\n",
      "a major limitation in the success of these systems\n",
      "a result\n",
      "a great deal\n",
      "research\n",
      "a great deal of research\n",
      "methods\n",
      "more\n",
      "limited amounts\n",
      "data\n",
      "limited amounts of data\n",
      "more effectively learning from limited amounts of data\n",
      "methods of more effectively learning from limited amounts of data\n",
      "Recent research\n",
      "unsupervised and semi-supervised learning algorithms\n",
      "Such algorithms\n",
      "data\n",
      "the desired answers\n",
      "data that has not been hand-annotated with the desired answers\n",
      "a combination\n",
      "annotated and non-annotated data\n",
      "a combination of annotated and non-annotated data\n",
      "this task\n",
      "supervised learning\n",
      "less accurate results\n",
      "a given amount\n",
      "input data\n",
      "a given amount of input data\n",
      "less accurate results for a given amount of input data\n",
      "there\n",
      "an enormous amount\n",
      "non-annotated data\n",
      "non-annotated data available\n",
      "an enormous amount of non-annotated data available\n",
      "other things\n",
      "the entire content\n",
      "the World Wide Web\n",
      "the entire content of the World Wide Web\n",
      "the inferior results\n",
      "an enormous amount of non-annotated data available -LRB- including , among other things , the entire content of the World Wide Web -RRB- , which can often make up for the inferior results\n",
      "NLP\n",
      "machine learning Modern NLP algorithms\n",
      "NLP using machine learning Modern NLP algorithms\n",
      "machine learning\n",
      "statistical machine learning\n",
      "machine learning , especially statistical machine learning\n",
      "The paradigm\n",
      "machine learning\n",
      "The paradigm of machine learning\n",
      "that\n",
      "most prior attempts\n",
      "that of most prior attempts\n",
      "language processing\n",
      "implementations\n",
      "language-processing tasks\n",
      "implementations of language-processing tasks\n",
      "the direct hand coding\n",
      "large sets\n",
      "rules\n",
      "large sets of rules\n",
      "the direct hand coding of large sets of rules\n",
      "The machine-learning paradigm\n",
      "general learning algorithms\n",
      "general learning algorithms - often\n",
      "statistical inference\n",
      "such rules\n",
      "the analysis\n",
      "large corpora\n",
      "typical real-world examples\n",
      "large corpora of typical real-world examples\n",
      "the analysis of large corpora of typical real-world examples\n",
      "A corpus\n",
      "plural\n",
      "`` corpora ''\n",
      "plural , `` corpora ''\n",
      "A corpus -LRB- plural , `` corpora '' -RRB-\n",
      "a set\n",
      "documents\n",
      "individual sentences\n",
      "the correct values\n",
      "documents -LRB- or sometimes , individual sentences -RRB- that have been hand-annotated with the correct values to be learned\n",
      "a set of documents -LRB- or sometimes , individual sentences -RRB- that have been hand-annotated with the correct values to be learned\n",
      "Many different classes\n",
      "machine learning algorithms\n",
      "Many different classes of machine learning algorithms\n",
      "NLP tasks\n",
      "These algorithms\n",
      "as input\n",
      "a large set\n",
      "`` features ''\n",
      "the input data\n",
      "`` features '' that are generated from the input data\n",
      "a large set of `` features '' that are generated from the input data\n",
      "Some\n",
      "the earliest-used algorithms\n",
      "decision trees\n",
      "Some of the earliest-used algorithms , such as decision trees ,\n",
      "systems\n",
      "hard if-then rules\n",
      "the systems\n",
      "hand-written rules\n",
      "the systems of hand-written rules that were then common\n",
      "hard if-then rules similar to the systems of hand-written rules that were then common\n",
      "systems of hard if-then rules similar to the systems of hand-written rules that were then common\n",
      "research\n",
      "statistical models\n",
      "soft , probabilistic decisions\n",
      "real-valued weights\n",
      "each input feature\n",
      "statistical models , which make soft , probabilistic decisions based on attaching real-valued weights to each input feature\n",
      "Such models\n",
      "the advantage\n",
      "they\n",
      "the relative certainty\n",
      "many different possible answers\n",
      "only one\n",
      "many different possible answers rather than only one\n",
      "the relative certainty of many different possible answers rather than only one\n",
      "more reliable results\n",
      "such a model\n",
      "a component\n",
      "a larger system\n",
      "a component of a larger system\n",
      "Systems\n",
      "machine-learning algorithms\n",
      "Systems based on machine-learning algorithms\n",
      "many advantages\n",
      "hand-produced rules\n",
      "many advantages over hand-produced rules\n",
      "The learning procedures\n",
      "machine learning\n",
      "The learning procedures used during machine learning\n",
      "the most common cases\n",
      "rules\n",
      "hand\n",
      "it\n",
      "all\n",
      "the effort\n",
      "the most common cases , whereas when writing rules by hand it is often not obvious at all where the effort should be directed\n",
      "Automatic\n",
      "procedures\n",
      "Automatic learning procedures\n",
      "use\n",
      "statistical inference algorithms\n",
      "use of statistical inference algorithms\n",
      "models\n",
      "unfamiliar input\n",
      "words or structures\n",
      "words or structures that have not been seen before\n",
      "e.g.\n",
      "words or words\n",
      "words or words accidentally omitted\n",
      "e.g. with misspelled words or words accidentally omitted\n",
      "erroneous input -LRB- e.g. with misspelled words or words accidentally omitted -RRB-\n",
      "models that are robust to unfamiliar input -LRB- e.g. containing words or structures that have not been seen before -RRB- and to erroneous input -LRB- e.g. with misspelled words or words accidentally omitted -RRB-\n",
      "such input\n",
      "hand-written rules\n",
      "such input gracefully with hand-written rules -- or more\n",
      "systems\n",
      "hand-written rules\n",
      "soft decisions\n",
      "soft decisions -- extremely difficult , error-prone and time-consuming\n",
      "systems of hand-written rules that make soft decisions -- extremely difficult , error-prone and time-consuming\n",
      "Systems\n",
      "the rules\n",
      "Systems based on automatically learning the rules\n",
      "more input data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "systems\n",
      "hand-written rules\n",
      "systems based on hand-written rules\n",
      "the complexity\n",
      "the rules\n",
      "a much more difficult task\n",
      "the rules , which is a much more difficult task\n",
      "the complexity of the rules , which is a much more difficult task\n",
      "there\n",
      "a limit\n",
      "the complexity\n",
      "systems\n",
      "hand-crafted rules\n",
      "the systems\n",
      "hand-crafted rules , beyond which the systems become more and more unmanageable\n",
      "systems based on hand-crafted rules , beyond which the systems become more and more unmanageable\n",
      "the complexity of systems based on hand-crafted rules , beyond which the systems become more and more unmanageable\n",
      "a limit to the complexity of systems based on hand-crafted rules , beyond which the systems become more and more unmanageable\n",
      "more data\n",
      "input\n",
      "machine-learning systems\n",
      "a corresponding increase\n",
      "the number\n",
      "man-hours\n",
      "the number of man-hours\n",
      "a corresponding increase in the number of man-hours\n",
      "significant increases\n",
      "the complexity\n",
      "the annotation process\n",
      "the complexity of the annotation process\n",
      "significant increases in the complexity of the annotation process\n",
      "The subfield\n",
      "NLP\n",
      "approaches\n",
      "Natural Language Learning\n",
      "NLL\n",
      "Natural Language Learning -LRB- NLL -RRB-\n",
      "its conference CoNLL and peak body\n",
      "SIGNLL\n",
      "NLP devoted to learning approaches is known as Natural Language Learning -LRB- NLL -RRB- and its conference CoNLL and peak body SIGNLL\n",
      "The subfield of NLP devoted to learning approaches is known as Natural Language Learning -LRB- NLL -RRB- and its conference CoNLL and peak body SIGNLL\n",
      "ACL\n",
      "their links\n",
      "Computational Linguistics\n",
      "Language Acquisition\n",
      "Computational Linguistics and Language Acquisition\n",
      "the aims\n",
      "computational language\n",
      "research\n",
      "computational language learning research\n",
      "the aims of computational language learning research\n",
      "more\n",
      "human language acquisition\n",
      "psycholinguistics\n",
      "human language acquisition , or psycholinguistics\n",
      "NLL\n",
      "the related field\n",
      "Computational Psycholinguistics\n",
      "the related field of Computational Psycholinguistics\n"
     ]
    }
   ],
   "source": [
    "# sentence列挙、1文ずつ処理\n",
    "for parse in root.iterfind('./document/sentences/sentence/parse'):\n",
    "    result = []\n",
    "    ParseAndExtractNP(parse.text.strip(), result)\n",
    "    print(*result, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
