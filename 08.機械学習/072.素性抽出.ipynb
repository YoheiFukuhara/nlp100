{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "極性分析に有用そうな素性を各自で設計し，学習データから素性を抽出せよ．素性としては，レビューからストップワードを除去し，各単語をステミング処理したものが最低限のベースラインとなるであろう．\n",
    "\n",
    "\n",
    "ステミングではなくて、複数形を単数形にするたどの処理の方がベター"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/i348221/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/i348221/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/i348221/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/i348221/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# プロセッサをデフォルトの全指定にするおｔ遅かったので最低限に絞る\n",
    "# https://stanfordnlp.github.io/stanfordnlp/processors.html\n",
    "nlp = stanfordnlp.Pipeline(processors='tokenize,pos,lemma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag は Universal POS tags に準拠していそう\n",
    "# https://universaldependencies.org/u/pos/\n",
    "EXC_POS = {'PUNCT',   # 句読点\n",
    "           'X',       # その他\n",
    "           'SYM',     # 記号\n",
    "           'PART',    # 助詞('sなど)\n",
    "           'NUM'}     # 番号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -1 it's not original enough .\n",
      "\n",
      "original original ADJ\n",
      "enough enough ADJ\n",
      "1 -1 gibney and jarecki just want to string the bastard up .\n",
      "\n",
      "gibney gibney NOUN\n",
      "jarecki jarecki PROPN\n",
      "want want VERB\n",
      "string string VERB\n",
      "bastard bastard NOUN\n",
      "2 -1 an overstylized , puréed mélange of sex , psychology , drugs and philosophy . sometimes entertaining , sometimes indulgent -- but never less than pure wankery .\n",
      "\n",
      "overstylized overstylize VERB\n",
      "puréed pur VERB\n",
      "mélange mélange NOUN\n",
      "sex sex NOUN\n",
      "psychology psychology NOUN\n",
      "drugs drug NOUN\n",
      "philosophy philosophy NOUN\n",
      "sometimes sometimes ADV\n",
      "entertaining entertaining ADJ\n",
      "sometimes sometimes ADV\n",
      "indulgent indulgent ADJ\n",
      "never never ADV\n",
      "less less ADJ\n",
      "pure pure ADJ\n",
      "wankery wankery NOUN\n",
      "3 +1 woo's fights have a distinct flair . his warriors collide in balletic explosion that implies an underlying order throughout the chaos .\n",
      "\n",
      "woo woo NOUN\n",
      "fights fight NOUN\n",
      "distinct distinct ADJ\n",
      "flair flair NOUN\n",
      "warriors warrior NOUN\n",
      "collide collide VERB\n",
      "balletic balletic ADJ\n",
      "explosion explosion NOUN\n",
      "implies imply VERB\n",
      "underlying underlying ADJ\n",
      "order order NOUN\n",
      "throughout throughout ADP\n",
      "chaos chaos NOUN\n"
     ]
    }
   ],
   "source": [
    "# 3件確認のみ\n",
    "with open('./sentiment.txt') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        doc = nlp(line)\n",
    "        print(i, line)\n",
    "        for sentence in doc.sentences:\n",
    "            for word in sentence.words:\n",
    "                if   word.upos not in EXC_POS\\\n",
    "                 and word.lemma not in stop_words:\n",
    "                    print(word.text, word.lemma, word.upos)\n",
    "        if i == 3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10661"
     ]
    }
   ],
   "source": [
    "# 警告非表示\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "lemma = []\n",
    "pos = []\n",
    "\n",
    "pd_words = {'lemma':[], 'pos':[]}\n",
    "with open('./sentiment.txt') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        print(\"\\r{0}\".format(i), end=\"\")\n",
    "        doc = nlp(line)\n",
    "        for sentence in doc.sentences:\n",
    "            for word in sentence.words:\n",
    "                if   word.upos not in EXC_POS\\\n",
    "                 and word.lemma not in stop_words:\n",
    "                    lemma.append(word.lemma)\n",
    "                    pos.append(word.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    pd_words['lemma'].append(word.lemma)\n",
    "                    pd_words['pos'].append(word.upos)\n",
    "df_words = pd.DataFrame(pd_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words.head()\n",
    "df_words.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_count = df_words['lemma'].value_counts()\n",
    "print(lemma_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count = df_words['pos'].value_counts()\n",
    "print(pos_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
