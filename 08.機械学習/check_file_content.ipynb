{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2780 +1 os problemas têm início a partir do momento em que saímos do cinema e começamos a pensar sobre o que acabamos de ver . É então que sinais realmente desaponta .\n",
      "\n",
      "2857 +1 É uma pena que , mais tarde , o próprio filme abandone o tom de paródia e passe a utilizar os mesmos clichês que havia satirizado .\n",
      "\n",
      "10189 +1 o Último suspeito ganha força ao também funcionar em uma esfera adicional : a do drama familiar .\n",
      "\n",
      "10445 -1 a era do gelo diverte , mas não convence . É um passatempo descompromissado  e só .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./sentiment.txt') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if line.lower() != line:\n",
    "            print(i, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/i348221/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'look'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl.lemmatize(\"looked\", pos=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'm\", 'a', 'student']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(\"[\\w']+\")\n",
    "print(tokenizer.tokenize(\"I'm a student.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['1', \"it's\", 'not', 'original', 'enough']\n",
      "1 ['1', 'gibney', 'and', 'jarecki', 'just', 'want', 'to', 'string', 'the', 'bastard', 'up']\n",
      "2 ['1', 'an', 'overstylized', 'puréed', 'mélange', 'of', 'sex', 'psychology', 'drugs', 'and', 'philosophy', 'sometimes', 'entertaining', 'sometimes', 'indulgent', 'but', 'never', 'less', 'than', 'pure', 'wankery']\n",
      "3 ['1', \"woo's\", 'fights', 'have', 'a', 'distinct', 'flair', 'his', 'warriors', 'collide', 'in', 'balletic', 'explosion', 'that', 'implies', 'an', 'underlying', 'order', 'throughout', 'the', 'chaos']\n",
      "4 ['1', 'one', 'of', 'the', 'most', 'depressing', 'movie', 'going', 'experiences', 'i', 'can', 'think', 'of', 'is', 'to', 'sit', 'through', 'about', '90', 'minutes', 'of', 'a', 'so', 'called', \"'comedy'\", 'and', 'not', 'laugh', 'once']\n",
      "5 ['1', 'best', 'described', 'as', 'i', 'know', 'what', 'you', 'did', 'last', 'winter']\n",
      "6 ['1', 'as', 'a', 'science', 'fiction', 'movie', 'minority', 'report', 'astounds']\n",
      "7 ['1', 'the', \"auteur's\", 'ear', 'for', 'the', 'way', 'fears', 'and', 'slights', 'are', 'telegraphed', 'in', 'the', 'most', 'blithe', 'exchanges', 'gives', 'the', 'film', 'its', 'lingering', 'tug']\n",
      "8 ['1', \"costner's\", 'warm', 'milk', 'persona', 'is', 'just', 'as', 'ill', 'fitting', 'as', \"shadyac's\", 'perfunctory', 'directing', 'chops', 'and', 'some', 'of', 'the', 'more', 'overtly', 'silly', 'dialogue', 'would', 'sink', 'laurence', 'olivier']\n",
      "9 ['1', 'what', 'was', 'once', 'original', 'has', 'been', 'co', 'opted', 'so', 'frequently', 'that', 'it', 'now', 'seems', 'pedestrian']\n",
      "10 ['1', 'waydowntown', 'may', 'not', 'be', 'an', 'important', 'movie', 'or', 'even', 'a', 'good', 'one', 'but', 'it', 'provides', 'a', 'nice', 'change', 'of', 'mindless', 'pace', 'in', 'collision', 'with', 'the', 'hot', 'oscar', 'season', 'currently', 'underway']\n",
      "11 ['1', 'apuestas', 'fuertes', 'para', 'el', 'futuro', 'del', 'director', 'y', 'apuestas', 'bien', 'fundadas', 'pues', 'la', 'suerte', 'ya', 'la', 'tiene', 'y', 'la', 'cinta', 'lo', 'comprueba']\n",
      "12 ['1', 'trailer', 'park', 'magnolia', 'too', 'long', 'too', 'cutesy', 'too', 'sure', 'of', 'its', 'own', 'importance', 'and', 'possessed', 'of', 'that', 'peculiar', 'tension', 'of', 'being', 'too', 'dense', 'about', 'nothing', 'at', 'all']\n",
      "13 ['1', 'birthday', 'girl', 'is', 'an', \"actor's\", 'movie', 'first', 'and', 'foremost']\n",
      "14 ['1', 'director', 'rob', 'marshall', 'went', 'out', 'gunning', 'to', 'make', 'a', 'great', 'one']\n",
      "15 ['1', 'this', 'is', 'a', 'movie', 'filled', 'with', 'unlikable', 'spiteful', 'idiots', 'whether', 'or', 'not', 'their', 'friendship', 'is', 'salvaged', 'makes', 'no', 'difference', 'in', 'the', 'least']\n",
      "16 ['1', 'at', 'the', 'end', 'when', 'the', 'now', 'computerized', 'yoda', 'finally', 'reveals', 'his', 'martial', 'artistry', 'the', 'film', 'ascends', 'to', 'a', 'kinetic', 'life', 'so', 'teeming', 'that', 'even', 'cranky', 'adults', 'may', 'rediscover', 'the', 'quivering', 'kid', 'inside']\n",
      "17 ['1', 'by', 'the', 'time', 'the', 'surprise', 'ending', 'is', 'revealed', 'interest', 'cannot', 'be', 'revived']\n",
      "18 ['1', 'extremely', 'bad']\n",
      "19 ['1', 'was', 'i', 'scared', 'only', 'at', 'the', 'prospect', 'of', \"beck's\", 'next', 'project', \"let's\", 'see', 'a', 'haunted', 'house', 'a', 'haunted', 'ship', \"what's\", 'next', 'ghost', 'blimp']\n",
      "20 ['1', 'spinning', 'a', 'web', 'of', 'dazzling', 'entertainment', 'may', 'be', 'overstating', 'it', 'but', 'spider', 'man', 'certainly', 'delivers', 'the', 'goods']\n",
      "21 ['1', 'borrows', 'a', 'bit', 'from', 'the', 'classics', 'wait', 'until', 'dark', 'and', 'extremities', 'but', 'in', 'terms', 'of', 'its', 'style', 'the', 'movie', 'is', 'in', 'a', 'class', 'by', 'itself']\n",
      "22 ['1', 'as', 'the', 'story', 'moves', 'inexorably', 'through', 'its', 'seven', 'day', 'timeframe', 'the', 'picture', 'becomes', 'increasingly', 'mesmerizing']\n",
      "23 ['1', 'just', 'about', 'all', 'of', 'the', 'film', 'is', 'confusing', 'on', 'one', 'level', 'or', 'another', 'making', 'ararat', 'far', 'more', 'demanding', 'than', 'it', 'needs', 'to', 'be']\n",
      "24 ['1', 'as', 'relationships', 'shift', 'director', 'robert', 'j', 'siegel', 'allows', 'the', 'characters', 'to', 'inhabit', 'their', 'world', 'without', 'cleaving', 'to', 'a', 'narrative', 'arc']\n",
      "25 ['1', \"hollywood's\", 'answer', 'to', 'an', 'air', 'ball']\n",
      "26 ['1', 'too', 'many', 'improbabilities', 'and', 'rose', 'colored', 'situations', 'temper', 'what', \"could've\", 'been', 'an', 'impacting', 'film']\n",
      "27 ['1', 'stevens', 'is', 'so', 'stoked', 'to', 'make', 'an', 'important', 'film', 'about', 'human', 'infidelity', 'and', 'happenstance', 'that', 'he', 'tosses', 'a', 'kitchen', 'sink', 'onto', 'a', 'story', 'already', 'overladen', 'with', 'plot', 'conceits']\n",
      "28 ['1', 'the', 'movie', 'is', 'like', 'a', 'year', 'late', 'for', 'tapping', 'into', 'our', 'reality', 'tv', 'obsession', 'and', 'even', 'tardier', 'for', 'exploiting', 'the', 'novelty', 'of', 'the', 'webcast']\n",
      "29 ['1', 'an', 'energetic', 'violent', 'movie', 'with', 'a', 'momentum', 'that', 'never', 'lets', 'up']\n",
      "30 ['1', \"here's\", 'a', 'case', 'of', 'two', 'actors', 'who', 'do', 'everything', 'humanly', 'possible', 'to', 'create', 'characters', 'who', 'are', 'sweet', 'and', 'believable', 'and', 'are', 'defeated', 'by', 'a', 'screenplay', 'that', 'forces', 'them', 'into', 'bizarre', 'implausible', 'behavior']\n"
     ]
    }
   ],
   "source": [
    "with open('./sentiment.txt') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        print(i, tokenizer.tokenize(line))\n",
    "        if i == 30:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default treebank \"en_ewt\" for language \"en\".\n",
      "Would you like to download the models for: en_ewt now? (Y/n)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default download directory: /home/i348221/stanfordnlp_resources\n",
      "Hit enter to continue or type an alternate directory.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading models for: en_ewt\n",
      "Download location: /home/i348221/stanfordnlp_resources/en_ewt_models.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235M/235M [00:51<00:00, 4.57MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete.  Models saved to: /home/i348221/stanfordnlp_resources/en_ewt_models.zip\n",
      "Extracting models file for: en_ewt\n",
      "Cleaning up...Done.\n"
     ]
    }
   ],
   "source": [
    "stanfordnlp.download('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/i348221/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/i348221/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/i348221/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/i348221/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/home/i348221/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/home/i348221/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "nlp = stanfordnlp.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Barack Obama was born in Hawaii.  He was elected president in 2008.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Barack', '4', 'nsubj:pass')\n",
      "('Obama', '1', 'flat')\n",
      "('was', '4', 'aux:pass')\n",
      "('born', '0', 'root')\n",
      "('in', '6', 'case')\n",
      "('Hawaii', '4', 'obl')\n",
      "('.', '4', 'punct')\n"
     ]
    }
   ],
   "source": [
    "doc.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('He', '3', 'nsubj:pass')\n",
      "('was', '3', 'aux:pass')\n",
      "('elected', '0', 'root')\n",
      "('president', '3', 'xcomp')\n",
      "('in', '6', 'case')\n",
      "('2008', '3', 'obl')\n",
      "('.', '3', 'punct')\n"
     ]
    }
   ],
   "source": [
    "doc.sentences[1].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('-', '7', 'punct')\n",
      "('1', '7', 'nummod')\n",
      "('it', '7', 'nsubj')\n",
      "(\"'s\", '7', 'cop')\n",
      "('not', '7', 'advmod')\n",
      "('original', '7', 'obl:npmod')\n",
      "('enough', '0', 'root')\n",
      "('.', '7', 'punct')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('-', '7', 'punct')\n",
      "('1', '3', 'nummod')\n",
      "('gibney', '7', 'nsubj')\n",
      "('and', '5', 'cc')\n",
      "('jarecki', '3', 'conj')\n",
      "('just', '7', 'advmod')\n",
      "('want', '0', 'root')\n",
      "('to', '9', 'mark')\n",
      "('string', '7', 'advcl')\n",
      "('the', '11', 'det')\n",
      "('bastard', '9', 'obj')\n",
      "('up', '9', 'compound:prt')\n",
      "('.', '7', 'punct')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('-', '7', 'punct')\n",
      "('1', '7', 'nummod')\n",
      "('an', '7', 'det')\n",
      "('overstylized', '7', 'amod')\n",
      "(',', '7', 'punct')\n",
      "('puréed', '7', 'amod')\n",
      "('mélange', '0', 'root')\n",
      "('of', '9', 'case')\n",
      "('sex', '7', 'nmod')\n",
      "(',', '11', 'punct')\n",
      "('psychology', '9', 'conj')\n",
      "(',', '13', 'punct')\n",
      "('drugs', '9', 'conj')\n",
      "('and', '15', 'cc')\n",
      "('philosophy', '9', 'conj')\n",
      "('.', '7', 'punct')\n",
      "('sometimes', '18', 'advmod')\n",
      "('entertaining', '7', 'amod')\n",
      "(',', '21', 'punct')\n",
      "('sometimes', '21', 'advmod')\n",
      "('indulgent', '18', 'conj')\n",
      "('--', '21', 'punct')\n",
      "('but', '28', 'cc')\n",
      "('never', '25', 'advmod')\n",
      "('less', '28', 'advmod')\n",
      "('than', '28', 'case')\n",
      "('pure', '28', 'amod')\n",
      "('wankery', '18', 'conj')\n",
      "('.', '18', 'punct')\n",
      "('+', '6', 'discourse')\n",
      "('1', '3', 'nummod')\n",
      "('woo', '5', 'nmod:poss')\n",
      "(\"'s\", '3', 'case')\n",
      "('fights', '6', 'nsubj')\n",
      "('have', '0', 'root')\n",
      "('a', '9', 'det')\n",
      "('distinct', '9', 'amod')\n",
      "('flair', '6', 'obj')\n",
      "('.', '6', 'punct')\n",
      "('his', '12', 'nmod:poss')\n",
      "('warriors', '13', 'nsubj')\n",
      "('collide', '6', 'parataxis')\n",
      "('in', '16', 'case')\n",
      "('balletic', '16', 'amod')\n",
      "('explosion', '13', 'obl')\n",
      "('that', '18', 'nsubj')\n",
      "('implies', '16', 'acl:relcl')\n",
      "('an', '21', 'det')\n",
      "('underlying', '21', 'amod')\n",
      "('order', '18', 'obj')\n",
      "('throughout', '24', 'case')\n",
      "('the', '24', 'det')\n",
      "('chaos', '21', 'nmod')\n",
      "('.', '6', 'punct')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "with open('./sentiment.txt') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        doc = nlp(line)\n",
    "        doc.sentences[0].print_dependencies()\n",
    "        if i == 3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- PUNCT\n",
      "1 X\n",
      "it PRON\n",
      "be AUX\n",
      "not PART\n",
      "original ADJ\n",
      "enough ADJ\n",
      ". PUNCT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- PUNCT\n",
      "1 NUM\n",
      "gibney NOUN\n",
      "and CCONJ\n",
      "jarecki PROPN\n",
      "just ADV\n",
      "want VERB\n",
      "to SCONJ\n",
      "string VERB\n",
      "the DET\n",
      "bastard NOUN\n",
      "up ADP\n",
      ". PUNCT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- PUNCT\n",
      "1 X\n",
      "a DET\n",
      "overstylize VERB\n",
      ", PUNCT\n",
      "pur VERB\n",
      "mélange NOUN\n",
      "of ADP\n",
      "sex NOUN\n",
      ", PUNCT\n",
      "psychology NOUN\n",
      ", PUNCT\n",
      "drug NOUN\n",
      "and CCONJ\n",
      "philosophy NOUN\n",
      ". PUNCT\n",
      "sometimes ADV\n",
      "entertaining ADJ\n",
      ", PUNCT\n",
      "sometimes ADV\n",
      "indulgent ADJ\n",
      "-- PUNCT\n",
      "but CCONJ\n",
      "never ADV\n",
      "less ADJ\n",
      "than ADP\n",
      "pure ADJ\n",
      "wankery NOUN\n",
      ". PUNCT\n",
      "+ SYM\n",
      "1 NUM\n",
      "woo NOUN\n",
      "'s PART\n",
      "fight NOUN\n",
      "have VERB\n",
      "a DET\n",
      "distinct ADJ\n",
      "flair NOUN\n",
      ". PUNCT\n",
      "he PRON\n",
      "warrior NOUN\n",
      "collide VERB\n",
      "in ADP\n",
      "balletic ADJ\n",
      "explosion NOUN\n",
      "that PRON\n",
      "imply VERB\n",
      "a DET\n",
      "underlying ADJ\n",
      "order NOUN\n",
      "throughout ADP\n",
      "the DET\n",
      "chaos NOUN\n",
      ". PUNCT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "lemma = []\n",
    "with open('./sentiment.txt') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        doc = nlp(line)\n",
    "        for sentence in doc.sentences:\n",
    "            for word in sentence.words:\n",
    "                if   word.upos not in exc_pos\n",
    "                 and word.lemma not in stop_words\n",
    "                print(word.lemma, word.upos)\n",
    "#                lemma.append(word.lemma)\n",
    "        if i == 3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '1',\n",
       " 'it',\n",
       " 'be',\n",
       " 'not',\n",
       " 'original',\n",
       " 'enough',\n",
       " '.',\n",
       " '-',\n",
       " '1',\n",
       " 'gibney',\n",
       " 'and',\n",
       " 'jarecki',\n",
       " 'just',\n",
       " 'want',\n",
       " 'to',\n",
       " 'string',\n",
       " 'the',\n",
       " 'bastard',\n",
       " 'up',\n",
       " '.',\n",
       " '-',\n",
       " '1',\n",
       " 'a',\n",
       " 'overstylize',\n",
       " ',',\n",
       " 'pur',\n",
       " 'mélange',\n",
       " 'of',\n",
       " 'sex',\n",
       " ',',\n",
       " 'psychology',\n",
       " ',',\n",
       " 'drug',\n",
       " 'and',\n",
       " 'philosophy',\n",
       " '.',\n",
       " 'sometimes',\n",
       " 'entertaining',\n",
       " ',',\n",
       " 'sometimes',\n",
       " 'indulgent',\n",
       " '--',\n",
       " 'but',\n",
       " 'never',\n",
       " 'less',\n",
       " 'than',\n",
       " 'pure',\n",
       " 'wankery',\n",
       " '.',\n",
       " '+',\n",
       " '1',\n",
       " 'woo',\n",
       " \"'s\",\n",
       " 'fight',\n",
       " 'have',\n",
       " 'a',\n",
       " 'distinct',\n",
       " 'flair',\n",
       " '.',\n",
       " 'he',\n",
       " 'warrior',\n",
       " 'collide',\n",
       " 'in',\n",
       " 'balletic',\n",
       " 'explosion',\n",
       " 'that',\n",
       " 'imply',\n",
       " 'a',\n",
       " 'underlying',\n",
       " 'order',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'chaos',\n",
       " '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
