{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文中のすべての名詞を含む文節に対し，その文節から構文木の根に至るパスを抽出せよ． ただし，構文木上のパスは以下の仕様を満たすものとする．\n",
    "\n",
    "- 各文節は（表層形の）形態素列で表現する\n",
    "- パスの開始文節から終了文節に至るまで，各文節の表現を\"->\"で連結する\n",
    "\n",
    "「吾輩はここで始めて人間というものを見た」という文（neko.txt.cabochaの8文目）から，次のような出力が得られるはずである．\n",
    "\n",
    "```\n",
    "吾輩は -> 見た\n",
    "ここで -> 始めて -> 人間という -> ものを -> 見た\n",
    "人間という -> ものを -> 見た\n",
    "ものを -> 見た\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 区切り文字\n",
    "separator = re.compile('\\t|,')\n",
    "\n",
    "# 係り受け\n",
    "dependancy = re.compile(r'''(?:\\*\\s\\d+\\s) # キャプチャ対象外\n",
    "                            (-?\\d+)       # 数字(係り先)\n",
    "                          ''', re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morph:\n",
    "    def __init__(self, line):\n",
    "        \n",
    "        #タブとカンマで分割\n",
    "        cols = separator.split(line)\n",
    "        \n",
    "        self.surface = cols[0] # 表層形(surface)\n",
    "        self.base = cols[7]    # 基本形(base)\n",
    "        self.pos = cols[1]     # 品詞(pos)\n",
    "        self.pos1 = cols[2]    # 品詞細分類1(pos1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunk:\n",
    "    def __init__(self, morphs, dst):\n",
    "        self.morphs = morphs\n",
    "        self.dst  = dst  # 係り先文節インデックス番号\n",
    "        \n",
    "        self.phrase = ''\n",
    "        self.noun = False\n",
    "        \n",
    "        for morph in morphs:\n",
    "            if morph.pos != '記号':\n",
    "                self.phrase += morph.surface # 記号以外の場合文節作成\n",
    "            if morph.pos == '名詞':\n",
    "                self.noun = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 10 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "morphs = []\n",
    "chunks = []\n",
    "sentences = []\n",
    "\n",
    "with open('./neko.txt.cabocha') as f:\n",
    "    \n",
    "    for line in f:\n",
    "        dependancies = dependancy.match(line)\n",
    "        \n",
    "        # EOSまたは係り受け解析結果でない場合\n",
    "        if not (line == 'EOS\\n' or dependancies):\n",
    "            morphs.append(Morph(line))\n",
    "            \n",
    "        # EOSまたは係り受け解析結果で、形態素解析結果がある場合\n",
    "        elif len(morphs) > 0:\n",
    "            chunks.append(Chunk(morphs, dst))\n",
    "            morphs = []\n",
    "       \n",
    "        # 係り受け結果の場合\n",
    "        if dependancies:\n",
    "            dst = int(dependancies.group(1))\n",
    "        \n",
    "        # EOSで係り受け結果がある場合\n",
    "        if line == 'EOS\\n' and len(chunks) > 0:\n",
    "            sentences.append(chunks)\n",
    "            chunks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \t 名前は -> 無い\n",
      "3 \t どこで -> 生れた -> かとんと -> つかぬ\n",
      "3 \t かとんと -> つかぬ\n",
      "3 \t 見当が -> つかぬ\n",
      "4 \t 何でも -> 薄暗い -> 泣いて -> 記憶している\n",
      "4 \t した所で -> 泣いて -> 記憶している\n",
      "4 \t いた事だけは -> 記憶している\n",
      "5 \t 吾輩は -> 見た\n",
      "5 \t ここで -> 始めて -> 人間という -> ものを -> 見た\n",
      "5 \t 人間という -> ものを -> 見た\n",
      "5 \t ものを -> 見た\n",
      "6 \t あとで -> 聞くと -> そうだ\n",
      "6 \t それは -> そうだ\n",
      "6 \t 書生という -> 人間中で -> 種族であった -> そうだ\n",
      "6 \t 人間中で -> 種族であった -> そうだ\n",
      "6 \t 一番 -> 獰悪な -> 種族であった -> そうだ\n",
      "6 \t 獰悪な -> 種族であった -> そうだ\n",
      "6 \t 種族であった -> そうだ\n",
      "7 \t 書生というのは -> 話である\n",
      "7 \t 我々を -> 捕えて -> 煮て -> 食うという -> 話である\n",
      "8 \t 当時は -> なかったから -> 思わなかった\n",
      "8 \t 何という -> 考も -> なかったから -> 思わなかった\n",
      "8 \t 考も -> なかったから -> 思わなかった\n",
      "9 \t 彼の -> 掌に -> 載せられて -> 持ち上げられた -> 時 -> フワフワした -> 感じが -> あったばかりである\n",
      "9 \t 掌に -> 載せられて -> 持ち上げられた -> 時 -> フワフワした -> 感じが -> あったばかりである\n",
      "9 \t スーと -> 持ち上げられた -> 時 -> フワフワした -> 感じが -> あったばかりである\n",
      "9 \t 時 -> フワフワした -> 感じが -> あったばかりである\n",
      "9 \t 感じが -> あったばかりである\n",
      "10 \t 掌の -> 上で -> 落ちついて -> 見たのが -> 人間という -> ものの -> 見始であろう\n",
      "10 \t 上で -> 落ちついて -> 見たのが -> 人間という -> ものの -> 見始であろう\n",
      "10 \t 書生の -> 顔を -> 見たのが -> 人間という -> ものの -> 見始であろう\n",
      "10 \t 顔を -> 見たのが -> 人間という -> ものの -> 見始であろう\n",
      "10 \t 見たのが -> 人間という -> ものの -> 見始であろう\n",
      "10 \t 人間という -> ものの -> 見始であろう\n",
      "10 \t ものの -> 見始であろう\n",
      "11 \t 時 -> ものだと -> 思った -> 感じが -> 残っている\n",
      "11 \t 妙な -> ものだと -> 思った -> 感じが -> 残っている\n",
      "11 \t ものだと -> 思った -> 感じが -> 残っている\n",
      "11 \t 感じが -> 残っている\n",
      "11 \t 今でも -> 残っている\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    for chunk in sentence:\n",
    "        if chunk.noun and chunk.dst != -1:\n",
    "            line = chunk.phrase\n",
    "            current_chunk = chunk\n",
    "            while current_chunk.dst != -1:\n",
    "                line = line + ' -> ' + sentence[current_chunk.dst].phrase\n",
    "                current_chunk = sentence[current_chunk.dst]\n",
    "            print(i, '\\t',line)\n",
    "    # 多いので制限\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
